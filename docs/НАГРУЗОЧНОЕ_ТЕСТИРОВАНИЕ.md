# 4.2 Нагрузочное тестирование (Benchmarking)

## 4.2.1 Методика тестирования и стенд

### Цели нагрузочного тестирования

Основной целью нагрузочного тестирования является оценка производительности системы MiniToolStream в различных режимах работы:

1. **Оценка пропускной способности** - измерение максимального количества сообщений, обрабатываемых системой в единицу времени
2. **Анализ задержек** - измерение времени доставки сообщений от отправителя к получателю
3. **Контроль потребления ресурсов** - мониторинг использования CPU, памяти, дисковых операций и сети
4. **Проверка стабильности** - оценка надежности системы под длительной нагрузкой
5. **Выявление узких мест** - определение компонентов, ограничивающих производительность

### Архитектура тестового стенда

Стенд для нагрузочного тестирования развернут на локальной машине с использованием Docker-контейнеров и включает следующие компоненты:

#### Основные компоненты системы

1. **MiniToolStream Ingress** (порт 50051)
   - gRPC-сервер для приема сообщений от publisher-клиентов
   - Обработка метаданных и подготовка сообщений к хранению
   - Взаимодействие с Tarantool для сохранения метаданных

2. **MiniToolStream Egress** (порт 50052)
   - gRPC-сервер для доставки сообщений subscriber-клиентам
   - Получение метаданных из Tarantool
   - Извлечение данных из MinIO

3. **Tarantool** (порт 3301)
   - In-memory база данных для метаданных сообщений
   - Индексирование по subject и sequence number
   - TTL-управление устаревшими записями

4. **MinIO** (порты 9000-9001)
   - S3-совместимое объектное хранилище для данных сообщений
   - Bucket-организация по subject
   - Хранение больших файлов и бинарных данных

5. **HashiCorp Vault** (порт 8200)
   - Управление секретами и конфигурацией
   - JWT-токены для аутентификации
   - Динамическая конфигурация клиентов

#### Система мониторинга и сбора метрик

1. **Prometheus** (порт 9090)
   - Сбор и хранение временных рядов метрик
   - Запросы и аггрегация данных
   - Долгосрочное хранение результатов тестов

2. **Pushgateway** (порт 9091)
   - Прием метрик от краткосрочных бенчмарков
   - Буферизация данных для Prometheus
   - Поддержка batch-операций

3. **Grafana** (порт 3000)
   - Визуализация метрик в реальном времени
   - Дашборды для анализа производительности
   - Графики throughput, latency, ресурсов

4. **cAdvisor** (порт 8081)
   - Мониторинг Docker-контейнеров
   - Метрики CPU, памяти, сети, дисков
   - Экспорт в Prometheus

5. **Node Exporter** (порт 9100)
   - Системные метрики хоста
   - CPU, память, диски, сеть
   - Экспорт в Prometheus

#### Кластер Kubernetes (K3s)

- **K3d-кластер** с 1 master и 2 worker-нодами
- Возможность масштабирования компонентов
- LoadBalancer на портах 8080, 8443, 6550

### Методология измерений

#### Собираемые метрики

**1. Метрики производительности (Performance Metrics)**

- **Throughput (пропускная способность)**
  - Messages per second (msg/sec) - количество сообщений в секунду
  - Megabytes per second (MB/sec) - объем данных в секунду
  - Total messages processed - общее количество обработанных сообщений
  - Total data transferred (MB) - общий объем переданных данных

- **Latency (задержка)**
  - Min latency - минимальная задержка доставки
  - Average latency - средняя задержка
  - P50 (медиана) - 50-й перцентиль
  - P95 - 95-й перцентиль (99% сообщений доставлены быстрее)
  - P99 - 99-й перцентиль
  - Max latency - максимальная задержка

**2. Метрики ресурсов (Resource Metrics)**

- **CPU Usage**
  - Процент использования CPU каждым контейнером
  - Пиковые значения под нагрузкой
  - Средние значения за период теста

- **Memory Usage**
  - Использование RAM в MB
  - Динамика потребления памяти
  - Утечки памяти (memory leaks)

- **Disk I/O**
  - Disk write (MB) - объем записанных данных
  - Disk read (MB) - объем прочитанных данных
  - IOPS - количество операций ввода-вывода

- **Network I/O**
  - Network TX (MB) - отправлено данных
  - Network RX (MB) - получено данных
  - Bandwidth utilization - использование пропускной способности

**3. Метрики надежности (Reliability Metrics)**

- **Error Rate**
  - Error count - количество ошибок
  - Error rate (%) - процент ошибочных запросов
  - Error types - типы ошибок (timeout, connection refused, etc.)

- **Success Rate**
  - Successful messages - успешно доставленные сообщения
  - Success rate (%) - процент успешных операций

#### Инструменты измерения

1. **Пользовательские Go-бенчмарки**
   - Расположение: `benchmarks/minitoolstream/cmd/`
   - Язык: Go 1.25
   - Библиотеки:
     - `github.com/moroshma/MiniToolStreamConnector/minitoolstream_connector` - клиентская библиотека
     - `gopkg.in/yaml.v3` - конфигурация тестов
     - `github.com/prometheus/client_golang` - экспорт метрик

2. **Docker Stats**
   - Команда: `docker stats --no-stream --format json`
   - Частота сбора: каждые 5-10 секунд
   - Контейнеры: Tarantool, MinIO, Ingress, Egress

3. **Prometheus Queries**
   - PromQL для агрегации метрик
   - Вычисление перцентилей
   - Построение временных рядов

### Конфигурация тестов

Все тесты настраиваются через YAML-файлы в директории `benchmarks/minitoolstream/configs/`:

```yaml
# Пример конфигурации
server:
  address: "localhost:50051"
  timeout: "30s"

test:
  name: "test-name"
  message_size: 10240        # Размер сообщения в байтах
  total_messages: 10000      # Общее количество сообщений
  num_producers: 10          # Количество producer'ов
  num_consumers: 5           # Количество consumer'ов
  target_rps: 1000          # Целевой RPS (0 = без ограничений)
  duration: "5m"            # Максимальная длительность
  warmup: "10s"             # Период прогрева

monitoring:
  enabled: true
  interval: "5s"
  containers:
    - "minitoolstream_connector-tarantool"
    - "minitoolstream_connector-minio"

prometheus:
  enabled: true
  pushgateway_url: "http://localhost:9091"
  push_interval: "5s"

output:
  results_dir: "../../results/minitoolstream"
  print_summary: true
  save_json: true
  save_csv: true
```

### Процедура запуска тестов

1. **Подготовка инфраструктуры**
   ```bash
   # Запуск MiniToolStream компонентов
   cd /Users/moroshma/go/DiplomaThesis/MiniToolStream
   docker-compose up -d

   # Запуск системы мониторинга
   cd benchmarks
   docker-compose -f docker-compose.monitoring.yml up -d
   ```

2. **Генерация тестовых данных**
   ```bash
   cd benchmarks/tools/scripts
   ./generate-test-files.sh
   ```

   Создаются файлы:
   - `test-10kb.bin` (10 KB)
   - `test-1mb.bin` (1 MB)
   - `test-10mb.bin` (10 MB)
   - `test-100mb.bin` (100 MB)
   - `test-1gb.bin` (1 GB, опционально)

3. **Запуск бенчмарка**
   ```bash
   cd benchmarks/minitoolstream/cmd/bench-small
   go run main.go -config ../../configs/small-files.yaml
   ```

4. **Сбор результатов**
   - JSON-отчеты: `benchmarks/results/minitoolstream/`
   - CSV-файлы для дальнейшего анализа
   - Метрики в Prometheus
   - Графики в Grafana

### Условия проведения тестов

**Аппаратная конфигурация:**
- CPU: современный многоядерный процессор
- RAM: минимум 8 GB для тестов с малыми сообщениями, 16+ GB для больших файлов
- Disk: SSD для минимизации влияния дисковой подсистемы
- Network: localhost (минимизация сетевых задержек)

**Программное окружение:**
- OS: macOS/Linux
- Docker версия: 20.10+
- Go версия: 1.25+
- K3s версия: 1.33+

**Изоляция тестов:**
- Все тесты выполняются на чистой инфраструктуре
- Между тестами выполняется очистка данных
- Исключение фоновых процессов, влияющих на производительность
- Отключение энергосберегающих режимов

---

## 4.2.2 Сценарий 1: Обработка малых сообщений (10KB)

### Описание сценария

Данный сценарий имитирует типичную нагрузку для систем обмена сообщениями, где передаются небольшие по объему данные с высокой частотой. Примеры использования:

- Логирование событий приложений
- Телеметрия и метрики от IoT-устройств
- Короткие текстовые сообщения
- JSON/XML документы небольшого размера
- Команды управления и уведомления

### Параметры теста

**Конфигурация из `small-files.yaml`:**

```yaml
test:
  name: "small-files-10kb"
  message_size: 10240        # 10 KB
  total_messages: 10000      # 10,000 сообщений
  num_producers: 10          # 10 параллельных publisher'ов
  num_consumers: 5           # 5 subscriber'ов
  target_rps: 1000          # 1,000 сообщений/сек
  duration: "5m"            # Максимум 5 минут
  warmup: "10s"             # 10 секунд прогрева
```

**Характеристики нагрузки:**

- **Общий объем данных**: 10,000 × 10 KB = ~97.66 MB
- **Целевая интенсивность**: 1,000 msg/sec (10 MB/sec)
- **Паттерн распределения**: равномерная нагрузка от 10 producer'ов
- **Subject**: `benchmark.small.files`

### Методика выполнения

1. **Период прогрева (Warmup - 10 секунд)**
   - Цель: стабилизация системы перед началом измерений
   - Действия:
     - Установка соединений с gRPC-сервером
     - Инициализация буферов и кэшей
     - Первые запросы к Tarantool и MinIO
   - Метрики в этом периоде не учитываются

2. **Фаза активной нагрузки**
   - 10 producer'ов одновременно отправляют сообщения
   - Каждый producer отправляет 1,000 сообщений (10,000 / 10)
   - Rate limiting: 100 msg/sec на producer (1,000 / 10)
   - Генерация случайных данных размером 10 KB:
     ```go
     payload := make([]byte, 10240)
     rand.Read(payload)
     ```

3. **Обработка на стороне Ingress**
   - Прием gRPC-запроса Publish()
   - Сохранение метаданных в Tarantool (subject, sequence, size, timestamp)
   - Загрузка payload в MinIO (bucket: subject, object: subject_sequence)
   - Возврат ответа клиенту с sequence number

4. **Параллельное чтение consumer'ами**
   - 5 subscriber'ов параллельно читают сообщения
   - Подписка на subject `benchmark.small.files`
   - Получение метаданных из Tarantool
   - Скачивание данных из MinIO
   - Измерение end-to-end latency

5. **Мониторинг ресурсов**
   - Каждые 5 секунд собираются метрики:
     ```bash
     docker stats --no-stream --format json \
       minitoolstream_connector-tarantool \
       minitoolstream_connector-minio
     ```
   - CPU, Memory, Network, Disk I/O

### Измеряемые метрики

**Throughput (пропускная способность):**
- **Messages per second**: фактическое количество обработанных сообщений в секунду
- **MB per second**: объем данных в мегабайтах в секунду
- **Сравнение с target**: отношение фактического throughput к целевому (1,000 msg/sec)

**Latency (задержка):**
- **Publish latency**: время от отправки сообщения до получения подтверждения
  - Включает: сериализацию, gRPC, запись в Tarantool, загрузку в MinIO
- **Subscribe latency**: время от запроса subscriber'а до получения данных
  - Включает: gRPC, чтение из Tarantool, скачивание из MinIO, десериализацию
- **End-to-end latency**: полное время от publish до subscribe
- **Перцентили**: P50, P95, P99 для оценки распределения задержек

**Resource utilization (использование ресурсов):**

*Tarantool:*
- CPU: ожидаемо высокое (частые записи/чтения метаданных)
- Memory: относительно стабильное (in-memory хранение)
- Disk I/O: средний (WAL и snapshots)

*MinIO:*
- CPU: средний (хеширование, сжатие)
- Memory: средний (буферизация)
- Disk I/O: высокий (10,000 × 10 KB записей)
- Network: средний (прием данных от Ingress)

*Ingress/Egress:*
- CPU: средний (gRPC обработка, сериализация)
- Memory: низкий-средний (буферы запросов)
- Network: высокий (прием/передача payload)

**Reliability (надежность):**
- **Success rate**: процент успешно доставленных сообщений (ожидается 100%)
- **Error rate**: количество и типы ошибок (timeout, connection refused)
- **Lost messages**: количество потерянных сообщений (ожидается 0)

### Ожидаемые результаты

На основе архитектуры системы и характеристик компонентов ожидаются следующие результаты:

**Throughput:**
- Messages/sec: 900-1,100 (близко к target 1,000)
- MB/sec: 9-11 MB/sec
- Общее время выполнения: ~10-12 секунд (10,000 / 1,000)

**Latency:**
- P50: 5-15 ms (медиана)
- P95: 20-40 ms
- P99: 50-100 ms
- Max: < 200 ms

**Resources:**
- Tarantool CPU: 20-40%
- Tarantool Memory: 100-200 MB
- MinIO CPU: 10-30%
- MinIO Memory: 200-400 MB
- Total Disk Write: ~100 MB
- Total Disk Read: ~100 MB (от subscriber'ов)
- Network TX/RX: ~200 MB total

**Reliability:**
- Success rate: 99.9%+
- Error rate: < 0.1%
- Lost messages: 0

### Анализ результатов

После выполнения теста анализируются следующие аспекты:

1. **Соответствие целевым показателям**
   - Достигнут ли target RPS 1,000 msg/sec?
   - Насколько стабильна пропускная способность?
   - Есть ли деградация производительности со временем?

2. **Распределение задержек**
   - Анализ гистограммы latency
   - Выявление аномалий (tail latency)
   - Оценка предсказуемости задержек

3. **Эффективность использования ресурсов**
   - CPU utilization vs throughput
   - Memory footprint и стабильность
   - Disk/Network I/O patterns
   - Bottleneck identification (узкие места)

4. **Масштабируемость**
   - Линейное ли увеличение throughput с числом producer'ов?
   - Влияние количества consumer'ов на latency
   - Limits и saturation points

### Пример запуска теста

```bash
# 1. Переход в директорию бенчмарка
cd /Users/moroshma/go/DiplomaThesis/MiniToolStream/benchmarks/minitoolstream/cmd/bench-small

# 2. Запуск теста с конфигурацией small-files
go run main.go -config ../../configs/small-files.yaml

# 3. Вывод в консоль
# Starting MiniToolStream benchmark: small-files-10kb
# Server: localhost:50051
# Message size: 10240 bytes (10.00 KB)
# Total messages: 10000
# Producers: 10
# Target RPS: 1000
#
# Warmup for 10s...
# Starting benchmark...
# Producer 0: starting (1000 messages)
# Producer 1: starting (1000 messages)
# ...
# Producer 9: starting (1000 messages)
#
# [Прогресс в реальном времени]
#
# Benchmark completed in 10.234s
#
# ================================================================================
# Benchmark Results: minitoolstream - small-files-10kb
# ================================================================================
# [Detailed metrics output]

# 4. Результаты сохраняются в:
# benchmarks/results/minitoolstream/small-files-YYYYMMDD-HHMMSS.json
# benchmarks/results/minitoolstream/small-files-YYYYMMDD-HHMMSS.csv
```

### Формат результатов (JSON)

```json
{
  "system": "minitoolstream",
  "test_name": "small-files-10kb",
  "timestamp": "2025-12-17T17:12:05Z",
  "config": {
    "message_size": 10240,
    "total_messages": 10000,
    "num_producers": 10,
    "num_consumers": 5,
    "target_rps": 1000
  },
  "throughput": {
    "msg_per_sec": 976.5,
    "mb_per_sec": 9.52,
    "total_messages": 10000,
    "total_mb": 97.66,
    "duration_sec": 10.24
  },
  "latency": {
    "min_ms": 3.2,
    "avg_ms": 12.4,
    "p50_ms": 10.8,
    "p95_ms": 28.3,
    "p99_ms": 65.7,
    "max_ms": 142.5
  },
  "resources": {
    "tarantool": {
      "cpu_percent": 32.5,
      "memory_mb": 156.3,
      "disk_write_mb": 102.4,
      "disk_read_mb": 8.2,
      "network_tx_mb": 12.5,
      "network_rx_mb": 98.1
    },
    "minio": {
      "cpu_percent": 18.7,
      "memory_mb": 324.6,
      "disk_write_mb": 97.8,
      "disk_read_mb": 97.6,
      "network_tx_mb": 98.2,
      "network_rx_mb": 12.3
    }
  },
  "reliability": {
    "success_count": 10000,
    "error_count": 0,
    "success_rate": 100.0,
    "error_rate": 0.0
  }
}
```

---

## 4.2.3 Сценарий 2: Передача больших файлов (1GB)

### Описание сценария

Сценарий тестирует способность системы обрабатывать большие файлы, что критично для следующих применений:

- Передача видео-файлов и стримов
- Обмен большими логами и дампами
- Резервное копирование и синхронизация данных
- Распространение обновлений и патчей
- Научные данные и датасеты
- Медицинские изображения (DICOM)

Этот сценарий проверяет:
- Стабильность работы с длительными операциями
- Эффективность управления памятью при больших payload
- Надежность передачи без потерь
- Производительность дисковой подсистемы и сети

### Параметры теста

**Конфигурация из `large-files.yaml`:**

```yaml
test:
  name: "large-files-1gb"
  message_size: 1073741824  # 1 GB (1024^3 bytes)
  total_messages: 10        # 10 файлов
  num_producers: 3          # 3 параллельных потока
  num_consumers: 1          # 1 subscriber
  target_rps: 0            # Без ограничений (as fast as possible)
  duration: "30m"          # Максимум 30 минут
  warmup: "0s"             # Без прогрева
```

**Характеристики нагрузки:**

- **Общий объем данных**: 10 × 1 GB = 10 GB
- **Целевая интенсивность**: максимально возможная (без искусственных ограничений)
- **Паттерн распределения**: 3 producer'а передают файлы последовательно
- **Subject**: `benchmark.large.files`
- **Timeout**: 600 секунд (10 минут на один файл)

### Методика выполнения

1. **Подготовка тестовых данных**
   ```bash
   # Генерация 1 GB файла
   dd if=/dev/urandom of=test-1gb.bin bs=1048576 count=1024
   ```
   - Случайные данные для предотвращения эффективного сжатия
   - Размер: ровно 1,073,741,824 байта

2. **Фаза передачи файлов**

   **Producer behavior:**
   - Каждый из 3 producer'ов отправляет 3-4 файла (всего 10)
   - Чтение файла порциями для минимизации потребления памяти:
     ```go
     const chunkSize = 64 * 1024 * 1024  // 64 MB chunks
     for offset := 0; offset < fileSize; offset += chunkSize {
         chunk := readChunk(file, offset, chunkSize)
         stream.Send(chunk)
     }
     ```
   - Отправка через gRPC streaming API
   - Измерение времени передачи каждого файла

3. **Обработка на стороне Ingress**

   **Streaming receive:**
   - Прием данных порциями через gRPC stream
   - Буферизация в памяти (ограниченная)
   - Постепенная запись в MinIO multipart upload:
     ```
     1. InitiateMultipartUpload()
     2. UploadPart() x N (для каждого chunk)
     3. CompleteMultipartUpload()
     ```
   - Atomic commit после успешной передачи всех частей

   **Metadata storage:**
   - После завершения multipart upload:
     ```sql
     INSERT INTO messages (subject, sequence, size, object_name, timestamp)
     VALUES ('benchmark.large.files', 50001, 1073741824,
             'benchmark.large.files_50001', '2025-12-17 17:30:00')
     ```
   - Компактная запись в Tarantool (~200 bytes vs 1 GB payload)

4. **Чтение consumer'ом**

   **Subscriber behavior:**
   - Подписка на `benchmark.large.files`
   - Получение метаданных из Tarantool
   - Streaming download из MinIO:
     ```go
     object := minioClient.GetObject("benchmark.large.files_50001")
     for {
         chunk := object.Read(64MB)
         process(chunk)
     }
     ```
   - Измерение времени скачивания
   - Валидация размера и checksums (если включено)

5. **Мониторинг ресурсов**
   - Более редкий интервал: каждые 10 секунд
   - Отслеживание тренда:
     - Постоянный рост disk usage на MinIO
     - Стабильное потребление памяти (streaming без накопления)
     - Высокая утилизация сети и дисков

### Измеряемые метрики

**Throughput (пропускная способность):**

Для больших файлов throughput измеряется иначе:

- **Files per minute**: количество файлов, переданных за минуту
- **MB per second**: средняя скорость передачи данных
  - Upload speed (producer → Ingress → MinIO)
  - Download speed (MinIO → Egress → subscriber)
- **Total transfer time**: время передачи всех 10 GB
- **Average file transfer time**: среднее время передачи одного файла (1 GB)

**Latency (задержка):**

Для больших файлов latency = transfer time:

- **Min transfer time**: самый быстрый файл
- **Max transfer time**: самый медленный файл
- **Average transfer time**: среднее время
- **Time to first byte (TTFB)**: время до начала получения данных subscriber'ом
- **Streaming latency**: задержка между отправкой chunk и его получением

**Resource utilization (использование ресурсов):**

*MinIO (критичный компонент):*
- **Disk Write**: ~10 GB записано
- **Disk Read**: ~10 GB прочитано (subscriber)
- **Disk IOPS**: операции записи/чтения
- **Disk space**: использование ~10 GB + overhead (~11 GB)
- **Memory**: стабильное использование для буферов
- **CPU**: умеренное (MD5/SHA256 хеширование, multipart управление)
- **Network**: высокая утилизация bandwidth

*Tarantool:*
- **Writes**: всего 10 операций INSERT (по одной на файл)
- **Memory**: минимальное увеличение (~2 KB для 10 записей)
- **CPU**: очень низкий (редкие операции)
- **Disk**: незначительный (WAL для 10 записей)

*Ingress/Egress:*
- **CPU**: низкий-средний (streaming passthrough)
- **Memory**: стабильный (streaming buffers ~128 MB)
- **Network RX (Ingress)**: ~10 GB от producer'ов
- **Network TX (Ingress)**: ~10 GB к MinIO
- **Network RX (Egress)**: ~10 GB от MinIO
- **Network TX (Egress)**: ~10 GB к subscriber'ам

**Reliability (надежность):**

- **Checksum validation**: проверка целостности через MD5/SHA256
- **Partial upload handling**: корректная обработка обрывов соединения
- **Retry mechanism**: автоматические повторы при ошибках
- **Success rate**: процент успешно переданных файлов
- **Data corruption**: обнаружение повреждений данных

### Ожидаемые результаты

**Throughput:**
- Transfer rate: зависит от disk/network speed, ожидается:
  - SSD: 200-500 MB/sec
  - HDD: 50-150 MB/sec
  - Network (localhost): 500-1000 MB/sec (не должно быть bottleneck)
- Files per minute:
  - При 200 MB/sec: ~12 файлов/мин (1 GB / 200 MB/sec ≈ 5 sec/file)
  - При 100 MB/sec: ~6 файлов/мин (1 GB / 100 MB/sec ≈ 10 sec/file)
- Total time для 10 GB:
  - Best case (500 MB/sec): ~20 секунд
  - Typical (200 MB/sec): ~50 секунд
  - Conservative (100 MB/sec): ~100 секунд

**Latency (transfer time per file):**
- Min: зависит от диска (2-10 сек для SSD)
- Average: 5-15 секунд
- Max: до 30 секунд (с учетом конкуренции от 3 producer'ов)
- TTFB: < 1 секунда (метаданные доступны сразу)

**Resources:**

*MinIO:*
- CPU: 15-30% (хеширование, multipart)
- Memory: 500-800 MB (стабильно)
- Disk Write: ~10 GB
- Disk Read: ~10 GB
- Disk Space used: ~11 GB (с учетом metadata)
- Network TX: ~10 GB
- Network RX: ~10 GB

*Tarantool:*
- CPU: < 5%
- Memory: +2-5 MB (10 записей)
- Disk Write: ~20 KB (WAL)

*Ingress:*
- CPU: 10-20%
- Memory: 200-400 MB (streaming buffers)
- Network RX: ~10 GB
- Network TX: ~10 GB

*Egress:*
- CPU: 10-20%
- Memory: 200-400 MB
- Network RX: ~10 GB
- Network TX: ~10 GB

**Reliability:**
- Success rate: 100% (все 10 файлов переданы)
- Checksum match: 100%
- Retries: 0 (при стабильной инфраструктуре)
- Data corruption: 0

### Особенности сценария

**1. Streaming vs Buffering**

Ключевое архитектурное решение — использование streaming вместо полной загрузки в память:

```
Без streaming (плохо):
Producer -> [1GB in memory] -> Ingress -> [1GB in memory] -> MinIO
Memory usage: 2+ GB

Со streaming (хорошо):
Producer -> [64MB chunk] -> Ingress -> [64MB chunk] -> MinIO
Memory usage: ~200 MB
```

**2. Multipart Upload в MinIO**

MinIO разбивает большие файлы на части (parts):
- Минимальный размер part: 5 MB
- Максимальный размер part: 5 GB
- Рекомендуемый размер: 64-128 MB
- Для 1 GB файла: ~16 parts по 64 MB

Преимущества:
- Параллельная загрузка частей
- Устойчивость к обрывам (resume upload)
- Эффективное использование сети

**3. Конкуренция producer'ов**

3 producer'а работают одновременно:
- Конкуренция за disk I/O на MinIO
- Конкуренция за network bandwidth (хотя localhost)
- Тестирование параллельной записи в разные objects

**4. Отсутствие rate limiting**

`target_rps: 0` означает:
- Максимально возможная скорость
- Ограничение только аппаратными ресурсами
- Тестирование peak performance

### Анализ результатов

После выполнения теста проводится анализ:

1. **Идентификация bottleneck**
   - Что ограничивает скорость: CPU, Disk, Network?
   - Анализ метрик `docker stats` для каждого компонента
   - Сравнение с теоретическим максимумом hardware

2. **Эффективность streaming**
   - Стабильность потребления памяти (отсутствие роста)
   - Smooth transfer rate без спайков
   - Отсутствие out-of-memory ошибок

3. **Надежность при длительных операциях**
   - Отсутствие timeouts (проверка 600s timeout)
   - Корректность multipart uploads
   - Отсутствие partial files в MinIO

4. **Масштабируемость**
   - Влияние количества producer'ов на throughput
   - Линейное ли увеличение скорости с числом потоков?
   - Saturation point (когда больше потоков не помогает)

5. **Сравнение upload vs download**
   - Симметрична ли скорость загрузки и скачивания?
   - Где больше задержек: в Ingress или Egress?

### Пример запуска теста

```bash
# 1. Убедиться, что есть место на диске (минимум 15 GB)
df -h /var/lib/docker  # или где хранятся Docker volumes

# 2. Переход в директорию бенчмарка
cd /Users/moroshma/go/DiplomaThesis/MiniToolStream/benchmarks/minitoolstream/cmd/bench-large

# 3. Запуск теста
go run main.go -config ../../configs/large-files.yaml

# 4. Вывод в консоль
# Starting MiniToolStream benchmark: large-files-1gb
# Server: localhost:50051
# Message size: 1073741824 bytes (1.00 GB)
# Total messages: 10
# Producers: 3
#
# Producer 0: starting (3 files)
# Producer 1: starting (3 files)
# Producer 2: starting (4 files)
#
# [File 1/10] Uploading... (Producer 0)
# [File 1/10] Uploaded in 8.234s (124.5 MB/sec)
#
# [File 2/10] Uploading... (Producer 1)
# [File 2/10] Uploaded in 7.891s (129.8 MB/sec)
# ...
#
# All 10 files transferred successfully
# Total time: 56.78s
# Average speed: 180.5 MB/sec
#
# ================================================================================
# Benchmark Results: minitoolstream - large-files-1gb
# ================================================================================
# [Detailed metrics]

# 5. Проверка данных в MinIO
docker exec -it minitoolstream_connector-minio mc ls local/benchmark.large.files/
# benchmark.large.files_50001  1.0 GB
# benchmark.large.files_50002  1.0 GB
# ...
# benchmark.large.files_50010  1.0 GB
```

### Формат результатов (JSON)

```json
{
  "system": "minitoolstream",
  "test_name": "large-files-1gb",
  "timestamp": "2025-12-17T17:30:00Z",
  "config": {
    "message_size": 1073741824,
    "total_messages": 10,
    "num_producers": 3,
    "num_consumers": 1,
    "target_rps": 0
  },
  "throughput": {
    "files_per_minute": 10.6,
    "mb_per_sec": 180.5,
    "total_gb": 10.0,
    "duration_sec": 56.78
  },
  "latency": {
    "min_transfer_time_sec": 4.23,
    "avg_transfer_time_sec": 5.68,
    "max_transfer_time_sec": 9.12,
    "ttfb_ms": 245
  },
  "files": [
    {
      "file_id": 1,
      "producer": 0,
      "size_bytes": 1073741824,
      "upload_time_sec": 8.234,
      "speed_mbps": 124.5,
      "sequence": 50001
    },
    // ... остальные 9 файлов
  ],
  "resources": {
    "minio": {
      "cpu_percent": 24.3,
      "memory_mb": 687.4,
      "disk_write_gb": 10.2,
      "disk_read_gb": 10.0,
      "disk_space_gb": 11.3,
      "network_tx_gb": 10.1,
      "network_rx_gb": 10.0
    },
    "tarantool": {
      "cpu_percent": 3.2,
      "memory_mb": 158.9,
      "disk_write_mb": 0.02,
      "disk_read_mb": 0.01
    },
    "ingress": {
      "cpu_percent": 15.8,
      "memory_mb": 342.1,
      "network_rx_gb": 10.0,
      "network_tx_gb": 10.1
    },
    "egress": {
      "cpu_percent": 14.2,
      "memory_mb": 298.6,
      "network_rx_gb": 10.0,
      "network_tx_gb": 10.0
    }
  },
  "reliability": {
    "success_count": 10,
    "error_count": 0,
    "success_rate": 100.0,
    "checksum_validation": "passed",
    "retries": 0
  }
}
```

### Оптимизации для больших файлов

На основе результатов этого теста можно выявить возможности оптимизации:

1. **Compression**: для сжимаемых данных (text, logs) включить gzip/lz4
2. **Chunk size tuning**: оптимальный размер chunk для баланса memory/performance
3. **Parallel multipart uploads**: параллельная загрузка parts в MinIO
4. **Network tuning**: увеличение TCP buffer size для длительных передач
5. **Disk scheduling**: использование noop/deadline scheduler для streaming I/O

---

## Выводы по нагрузочному тестированию

Комплексное нагрузочное тестирование по двум сценариям позволяет:

1. **Оценить универсальность системы** - способность эффективно работать как с малыми частыми сообщениями, так и с большими редкими файлами

2. **Выявить оптимальные области применения** - для каких workload'ов система показывает лучшие результаты

3. **Определить пределы масштабируемости** - максимальные throughput и размеры сообщений

4. **Обнаружить потенциальные проблемы** - bottleneck'и, memory leaks, stability issues

5. **Сравнить с конкурентами** - при наличии аналогичных тестов Kafka, RabbitMQ, NATS

Результаты тестирования будут использованы для:
- Оптимизации архитектуры и настроек
- Рекомендаций по deployment и конфигурации
- Документирования SLA и performance characteristics
- Маркетинговых материалов и технических спецификаций
